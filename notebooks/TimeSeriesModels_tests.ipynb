{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from minisom import MiniSom\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.clustering import TimeSeriesKMeans, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Days analysis\n",
    "### January 30th 2019, workday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('data/comed_month/comed_201901.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('data/comed_month/comed_201901.csv')\n",
    "df_data['date_time'] = pd.to_datetime(df_data.date_time)\n",
    "df_data = df_data.groupby(['zip5', 'date_time']).energy.sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namesofMySeries = list(df_data.zip5.unique())\n",
    "mySeries = []\n",
    "\n",
    "for zip_code in namesofMySeries:\n",
    "    df = df_data.query('zip5==@zip_code')[['date_time', 'energy']].set_index('date_time').sort_index()\n",
    "    mySeries.append(df)\n",
    "    if df.shape[0] != 1488:\n",
    "        print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mySeries)):\n",
    "    scaler = MinMaxScaler()\n",
    "    mySeries[i] = MinMaxScaler().fit_transform(mySeries[i])\n",
    "    mySeries[i]= mySeries[i].reshape(len(mySeries[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(60,5,figsize=(30,100))\n",
    "#fig.suptitle('Series')\n",
    "#for i in range(60):\n",
    "#    for j in range(5):\n",
    "#        if i*5+j+1>len(mySeries): # pass the others that we can't fill\n",
    "#            continue\n",
    "#        axs[i, j].plot(mySeries[i*5+j])\n",
    "#        axs[i, j].set_title(namesofMySeries[i*5+j])\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOM Lcustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_x = som_y = math.ceil(math.sqrt(math.sqrt(len(mySeries))))\n",
    "\n",
    "som = MiniSom(som_x, som_y, len(mySeries[0]), sigma=2, learning_rate = 3)\n",
    "\n",
    "som.random_weights_init(mySeries)\n",
    "som.train(mySeries, 50000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_som_series_averaged_center(som_x, som_y, win_map):\n",
    "    fig, axs = plt.subplots(som_x,som_y,figsize=(30,30))\n",
    "    fig.suptitle('Clusters')\n",
    "    for x in range(som_x):\n",
    "        for y in range(som_y):\n",
    "            cluster = (x,y)\n",
    "            if cluster in win_map.keys():\n",
    "                for series in win_map[cluster]:\n",
    "                    axs[cluster].plot(series,c=\"gray\",alpha=0.5) \n",
    "                axs[cluster].plot(np.average(np.vstack(win_map[cluster]),axis=0),c=\"red\")\n",
    "            cluster_number = x*som_y+y+1\n",
    "            axs[cluster].set_title(f\"Cluster {cluster_number}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_map = som.win_map(mySeries)\n",
    "# Returns the mapping of the winner nodes and inputs\n",
    "\n",
    "plot_som_series_averaged_center(som_x, som_y, win_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map = []\n",
    "for idx in range(len(mySeries)):\n",
    "    winner_node = som.winner(mySeries[idx])\n",
    "    cluster_map.append((namesofMySeries[idx],f\"Cluster {winner_node[0]*som_y+winner_node[1]+1}\"))\n",
    "\n",
    "df_clusters = pd.DataFrame(cluster_map,columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\").reset_index()\n",
    "\n",
    "df_clusters.Cluster.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = math.ceil(math.sqrt(len(mySeries)))\n",
    "km = TimeSeriesKMeans(n_clusters=cluster_count, metric=\"dtw\")\n",
    "labels = km.fit_predict(mySeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_sc = []\n",
    "cluster_counts = [2,5,7,10,13,15,17,20,25,30,35]\n",
    "for cluster_count in cluster_counts:\n",
    "    km = TimeSeriesKMeans(n_clusters=cluster_count, metric=\"dtw\")\n",
    "    labels = km.fit_predict(mySeries)\n",
    "    sil_sc.append(silhouette_score(mySeries, labels, metric='dtw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cluster_counts, sil_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count = math.ceil(math.sqrt(cluster_count))\n",
    "fig, axs = plt.subplots(plot_count,plot_count,figsize=(25,25))\n",
    "fig.suptitle('Clusters')\n",
    "row_i=0\n",
    "column_j=0\n",
    "for label in set(labels):\n",
    "    cluster = []\n",
    "    for i in range(len(labels)):\n",
    "            if(labels[i]==label):\n",
    "                axs[row_i, column_j].plot(mySeries[i],c=\"gray\",alpha=0.4)\n",
    "                cluster.append(mySeries[i])\n",
    "    if len(cluster) > 0:\n",
    "        axs[row_i, column_j].plot(np.average(np.vstack(cluster),axis=0),c=\"red\")\n",
    "    axs[row_i, column_j].set_title(\"Cluster \"+str(row_i*som_y+column_j))\n",
    "    column_j+=1\n",
    "    if column_j%plot_count == 0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole year: 2019\n",
    "Important months: January, July, April\n",
    "Week: July 15-21, January 28-Feb3, April 15-21\n",
    "Day: \n",
    "    work: January 30, July 10, 8 April\n",
    "    weekend: January 26, July 20, 7 April\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
