{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "px.set_mapbox_access_token(\"pk.eyJ1IjoiamdhY29zdGFzIiwiYSI6ImNsYWJwd3g1ZDAwaGUzb3Q0ZG04NDNndGgifQ.brk6kVA6biVSH0ovZ1dreA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_sex = [\"DP05_0002E\",\"DP05_0003E\"]\n",
    "columns_age = [\"DP05_0005E\",\"DP05_0006E\",\"DP05_0007E\",\"DP05_0008E\",\"DP05_0009E\",\"DP05_0010E\",\"DP05_0011E\",\"DP05_0012E\",\"DP05_0013E\",\"DP05_0014E\",\"DP05_0015E\",\"DP05_0016E\",\"DP05_0017E\"]\n",
    "columns_sex_age = [\"DP05_0026E\",\"DP05_0027E\", \"DP05_0030E\",\"DP05_0031E\"]\n",
    "columns_race = [\"DP05_0037E\", 'DP05_0038E', 'DP05_0039E', 'DP05_0044E', 'DP05_0052E', 'DP05_0057E']\n",
    "columns_income = ['S1901_C01_012E', 'S1901_C01_013E']\n",
    "columns_education = ['S1501_C01_002E', 'S1501_C01_003E', 'S1501_C01_004E', 'S1501_C01_005E', 'S1501_C01_007E', \n",
    "                     'S1501_C01_008E', 'S1501_C01_009E', 'S1501_C01_010E', 'S1501_C01_011E', 'S1501_C01_012E',\n",
    "                     'S1501_C01_013E', 'S1501_C01_014E', 'S1501_C01_015E', 'S1501_C01_017E', 'S1501_C01_018E',\n",
    "                     'S1501_C01_020E', 'S1501_C01_021E', 'S1501_C01_023E', 'S1501_C01_024E', 'S1501_C01_026E',\n",
    "                     'S1501_C01_027E', 'S1501_C01_021E', 'S1501_C01_023E', 'S1501_C01_024E', 'S1501_C01_026E',]\n",
    "\n",
    "best_columns_gb = ['DP05_0007E', 'S1501_C01_020E',\n",
    "       'DP05_0015E', 'DP05_0009E', 'DP05_0014E', 'DP05_0013E',\n",
    "       'DP05_0005E', 'DP05_0012E', 'S1501_C01_014E', 'DP05_0038E',\n",
    "       'S1501_C01_018E', 'DP05_0044E', 'DP05_0003E', 'DP05_0010E',\n",
    "       'S1501_C01_017E', 'Urban']\n",
    "\n",
    "best_columns_rf = ['S1501_C01_007E', 'DP05_0009E', 'DP05_0038E',\n",
    "       'S1501_C01_020E', 'DP05_0003E', 'DP05_0010E', 'DP05_0005E',\n",
    "       'DP05_0015E', 'DP05_0044E', 'S1501_C01_009E', 'DP05_0012E',\n",
    "       'S1501_C01_018E', 'S1501_C01_017E', 'Urban']\n",
    "\n",
    "\n",
    "data_urls = [\n",
    "    'Census_Clean_Zip5_IL_Household&Family_Married&Nonmarried_Income_2018.csv',\n",
    "    'Census_Clean_Zip5_IL_Sex_Age_Ethnicity_2018.csv',\n",
    "    'Census_Clean_Zip5_IL_EducationLevel_byAge_byIncome_Ethnicity_bySex.csv'\n",
    "]\n",
    "\n",
    "dict_col_names = pd.read_excel('data/census/variable_names.xlsx', sheet_name='raw').set_index('Code').to_dict()['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('data/comed_month/comed_201801.csv')\n",
    "df_data['date_time'] = pd.to_datetime(df_data.date_time)\n",
    "\n",
    "df_data = df_data.groupby(['zip5', 'date_time']).energy.sum().reset_index()\n",
    "df_data['weekday'] = df_data.date_time.dt.weekday\n",
    "gdf_zc = gpd.read_file('data/geo/Chicago_ZC.geojson')\n",
    "gdf_zc['GEOID20'] = gdf_zc['GEOID20'].astype(int)\n",
    "\n",
    "gdf_data = pd.merge(gdf_zc, df_data, left_on='GEOID20', right_on='zip5')\n",
    "gdf_data = gdf_data.groupby(['zip5', 'weekday']).sum().reset_index()\n",
    "gdf_data['zip5'] = gdf_data['zip5'].astype(str)\n",
    "\n",
    "for url in data_urls:\n",
    "    df_acs = pd.read_csv(f'data/census/{url}')\n",
    "    #dict_names = dict(zip(df_acs.columns, df_acs.loc[0].values))\n",
    "    df_acs = df_acs.drop(0)\n",
    "    df_acs['zip5'] = df_acs.NAME.str[6:]\n",
    "    gdf_data = pd.merge(gdf_data, df_acs, on='zip5')\n",
    "\n",
    "gdf_counties = gpd.read_file('data/geo/US_counties.json')\n",
    "\n",
    "gdf_zc_c = gdf_zc.sjoin(gdf_counties, how='left')\n",
    "city_zc = gdf_zc_c.query('NAME==\"Cook\"').GEOID20.astype(str).values\n",
    "\n",
    "gdf_data['Urban'] = np.where(gdf_data.zip5.isin(city_zc), 1, 0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gdf_data[columns_age+columns_sex+columns_income+columns_race+columns_education], gdf_data.energy\n",
    "\n",
    "X = X.rename(columns=dict_col_names)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=13\n",
    ")\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_train, y=reg.predict(X_train),\n",
    "                    mode='markers',\n",
    "                    name='Train data',\n",
    "                    marker = {'color': '#A34184',\n",
    "                              'size': 3}))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_test, y=reg.predict(X_test),\n",
    "                    mode='markers',\n",
    "                    name='Test data',\n",
    "                    marker = {'color': '#49A1A3',\n",
    "                              'size': 3}))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[0, 1.5e6], y=[0, 1.5e6],\n",
    "                    mode='lines',\n",
    "                    name='Theoretical solution',\n",
    "                    line=dict(color='black', \n",
    "                              width=1,\n",
    "                              dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=700,\n",
    "    title=\"Linear Regression Model\",\n",
    "    xaxis_title=\"Actual energy consumption (kWh)\", \n",
    "    yaxis_title=\"Predicted energy consumption (kWh)\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gdf_data[best_columns_rf], gdf_data.energy\n",
    "\n",
    "X = X.rename(columns=dict_col_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=13\n",
    ")\n",
    "\n",
    "reg = RandomForestRegressor(max_depth=9, random_state=0)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "r2_train = r2_score(y_train, reg.predict(X_train))\n",
    "r2 = r2_score(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "print(\"The R2 score (R2) on train set: {:.4f}\".format(r2_train))\n",
    "print(\"The R2 score (R2) on test set: {:.4f}\".format(r2))\n",
    "\n",
    "feature_importance = reg.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(X.columns)[sorted_idx])\n",
    "plt.title(\"Feature Importance (MDI)\")\n",
    "\n",
    "result = permutation_importance(\n",
    "    reg, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=np.array(X.columns)[sorted_idx],\n",
    ")\n",
    "plt.title(\"Permutation Importance (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_train, y=reg.predict(X_train),\n",
    "                    mode='markers',\n",
    "                    name='Train data',\n",
    "                    marker = {'color': '#A34184',\n",
    "                              'size': 3}))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_test, y=reg.predict(X_test),\n",
    "                    mode='markers',\n",
    "                    name='Test data',\n",
    "                    marker = {'color': '#49A1A3',\n",
    "                              'size': 3}))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[0, 1.5e6], y=[0, 1.5e6],\n",
    "                    mode='lines',\n",
    "                    name='Theoretical solution',\n",
    "                    line=dict(color='black', \n",
    "                              width=1,\n",
    "                              dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=700,\n",
    "    title=\"Random Forest Model\",\n",
    "    xaxis_title=\"Actual energy consumption (kWh)\", \n",
    "    yaxis_title=\"Predicted energy consumption (kWh)\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppport Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gdf_data[columns_age+columns_income+columns_education], gdf_data.energy\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=13\n",
    ")\n",
    "\n",
    "reg = SVR(C=1.0, epsilon=0.2, kernel='linear')\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "r2_train = r2_score(y_train, reg.predict(X_train))\n",
    "r2 = r2_score(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "print(\"The R2 score (R2) on train set: {:.4f}\".format(r2_train))\n",
    "print(\"The R2 score (R2) on test set: {:.4f}\".format(r2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = gdf_data[best_columns_gb], gdf_data.energy\n",
    "\n",
    "X = X.rename(columns=dict_col_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=13\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 800,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "reg = ensemble.GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "r2_train = r2_score(y_train, reg.predict(X_train))\n",
    "r2 = r2_score(y_test, reg.predict(X_test))\n",
    "print(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\n",
    "print(\"The R2 score (R2) on train set: {:.4f}\".format(r2_train))\n",
    "print(\"The R2 score (R2) on test set: {:.4f}\".format(r2))\n",
    "\n",
    "feature_importance = reg.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos, np.array(X.columns)[sorted_idx])\n",
    "plt.title(\"Feature Importance (MDI)\")\n",
    "\n",
    "result = permutation_importance(\n",
    "    reg, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=np.array(X.columns)[sorted_idx],\n",
    ")\n",
    "plt.title(\"Permutation Importance (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_train, y=reg.predict(X_train),\n",
    "                    mode='markers',\n",
    "                    name='Train data',\n",
    "                    marker = {'color': '#A34184',\n",
    "                              'size': 3}))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=y_test, y=reg.predict(X_test),\n",
    "                    mode='markers',\n",
    "                    name='Test data',\n",
    "                    marker = {'color': '#49A1A3',\n",
    "                              'size': 3}))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[0, 1.5e6], y=[0, 1.5e6],\n",
    "                    mode='lines',\n",
    "                    name='Theoretical solution',\n",
    "                    line=dict(color='black', \n",
    "                              width=1,\n",
    "                              dash='dash')))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=900,\n",
    "    height=700,\n",
    "    title=\"Gradient Boosting Model\",\n",
    "    xaxis_title=\"Actual energy consumption (kWh)\", \n",
    "    yaxis_title=\"Predicted energy consumption (kWh)\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(reg)\n",
    "shap_values = explainer(X) #Entire dataset\n",
    "shap_train = explainer(X_train) #Train set\n",
    "shap_test = explainer(X_test) #Test set - You can count the 14 dots per feature (i.e., size of test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'outputs/Dem'\n",
    "\n",
    "#Global Bar Plot\n",
    "fig = plt.figure() #Define an empty figure\n",
    "ax0 = fig.add_subplot(131)\n",
    "shap.plots.bar(shap_values, show=False)\n",
    "plt.title(\"Entire Dataset\")\n",
    "ax0 = fig.add_subplot(132)\n",
    "shap.plots.bar(shap_train, show=False)\n",
    "plt.title(\"Train Set\")\n",
    "ax0 = fig.add_subplot(133)\n",
    "shap.plots.bar(shap_test, show=False)\n",
    "plt.title(\"Test Set\")\n",
    "fig.set_size_inches(18,6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_name + '_SHAP_bar.png') #Saving the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Summary Plot\n",
    "shap.summary_plot(shap_test, show=False)\n",
    "plt.savefig(file_name + '_SHAP_summary.png') #Saving the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
