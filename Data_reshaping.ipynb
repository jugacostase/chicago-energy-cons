{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import zipfile\n",
    "import plotly.express as px\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_data = \"D:/CSUN/COMED/Comed DATA/201801.zip\" \n",
    "#zip = zipfile.ZipFile(path_data)\n",
    "#files= (zip.namelist())\n",
    "#month = '201711'\n",
    "#zips = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(f'data/comed/{month}/') for f in filenames]\n",
    "zips = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(f'data/comed/') for f in filenames]\n",
    "zips = zips\n",
    "N_zips = len(zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HR(x):\n",
    "    time_str = re.search(r'INTERVAL_HR(.*?)_ENERGY_QTY', x)[1]\n",
    "    return time_str\n",
    "\n",
    "selected_columns = ['ZIP_CODE', 'INTERVAL_READING_DATE', \n",
    "                    'DELIVERY_SERVICE_NAME', 'ACCOUNT_IDENTIFIER', \n",
    "                    'INTERVAL_HR0030_ENERGY_QTY', \n",
    "                    'INTERVAL_HR0100_ENERGY_QTY', 'INTERVAL_HR0130_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0200_ENERGY_QTY', 'INTERVAL_HR0230_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0300_ENERGY_QTY', 'INTERVAL_HR0330_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0400_ENERGY_QTY', 'INTERVAL_HR0430_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0500_ENERGY_QTY', 'INTERVAL_HR0530_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0600_ENERGY_QTY', 'INTERVAL_HR0630_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0700_ENERGY_QTY', 'INTERVAL_HR0730_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0800_ENERGY_QTY', 'INTERVAL_HR0830_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0900_ENERGY_QTY', 'INTERVAL_HR0930_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1000_ENERGY_QTY', 'INTERVAL_HR1030_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1100_ENERGY_QTY', 'INTERVAL_HR1130_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1200_ENERGY_QTY', 'INTERVAL_HR1230_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1300_ENERGY_QTY', 'INTERVAL_HR1330_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1400_ENERGY_QTY', 'INTERVAL_HR1430_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1500_ENERGY_QTY', 'INTERVAL_HR1530_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1600_ENERGY_QTY', 'INTERVAL_HR1630_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1700_ENERGY_QTY', 'INTERVAL_HR1730_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1800_ENERGY_QTY', 'INTERVAL_HR1830_ENERGY_QTY',\n",
    "                    'INTERVAL_HR1900_ENERGY_QTY', 'INTERVAL_HR1930_ENERGY_QTY',\n",
    "                    'INTERVAL_HR2000_ENERGY_QTY', 'INTERVAL_HR2030_ENERGY_QTY',\n",
    "                    'INTERVAL_HR2100_ENERGY_QTY', 'INTERVAL_HR2130_ENERGY_QTY',\n",
    "                    'INTERVAL_HR2200_ENERGY_QTY', 'INTERVAL_HR2230_ENERGY_QTY',\n",
    "                    'INTERVAL_HR2300_ENERGY_QTY', 'INTERVAL_HR2330_ENERGY_QTY',\n",
    "                    'INTERVAL_HR0000_ENERGY_QTY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_col_agg = {}\n",
    "\n",
    "for col in selected_columns[3:]:\n",
    "    dict_col_agg[col] = 'sum'\n",
    "#dict_col_agg['DELIVERY_SERVICE_NAME'] = lambda x: (x.value_counts().index, x.value_counts())\n",
    "#dict_col_agg['DELIVERY_SERVICE_CLASS'] = lambda x: (x.value_counts().index, x.value_counts())\n",
    "dict_col_agg['ACCOUNT_IDENTIFIER'] = 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = os.listdir('data/comed/')\n",
    "\n",
    "for month in months[11:]:\n",
    "    zips = [os.path.join(dirpath,f) for (dirpath, dirnames, filenames) in os.walk(f'data/comed/{month}/') for f in filenames if f.endswith('.zip')]\n",
    "    zips = zips\n",
    "    N_zips = len(zips)\n",
    "\n",
    "    df_total = pd.DataFrame()\n",
    "    #df_total = dd.from_pandas(df_total, npartitions=1)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for zip_path in zips:\n",
    "        zip = zipfile.ZipFile(zip_path)\n",
    "        count = count + 1\n",
    "        clear_output(wait=True)\n",
    "        print(f'{count}/{N_zips} --------> {round(100*count/N_zips, 3)} % progress in month {month} and file {zip_path}')\n",
    "        #for file in zip.namelist():\n",
    "        #zip2 = zipfile.ZipFile(f'data/comed/{month}/{file}')\n",
    "        #df = pd.read_csv(zip2.open(zip2.namelist()[0]))\n",
    "        df = pd.read_csv(zip.open(zip.namelist()[0]), on_bad_lines=lambda x: x[:2] + x[2+1 :], engine='python')\n",
    "        df['ZIP_CODE'] = df['ZIP_CODE'].astype(str)\n",
    "        df['ZIP_CODE'] = df['ZIP_CODE'].str[:5]\n",
    "        df = df.rename(columns={'INTERVAL_HR2400_ENERGY_QTY': 'INTERVAL_HR0000_ENERGY_QTY'})\n",
    "        df = df.groupby(['ZIP_CODE','INTERVAL_READING_DATE', 'DELIVERY_SERVICE_NAME']).agg(dict_col_agg).reset_index()\n",
    "        df_total = pd.concat([df_total,df])\n",
    "        df_total = df_total.groupby(['ZIP_CODE', 'INTERVAL_READING_DATE', 'DELIVERY_SERVICE_NAME']).sum().reset_index()\n",
    "        #df_total = dd.concat([df_total, dd.from_pandas(pd.read_csv(zip2.open(zip2.namelist()[0])), npartitions=1)])\n",
    "\n",
    "    df = df_total\n",
    "\n",
    "    #df['DELIVERY_SERVICE_NAME'] = df.DELIVERY_SERVICE_NAME.astype(str)\n",
    "    #df['DELIVERY_SERVICE_CLASS'] = df.DELIVERY_SERVICE_CLASS.astype(str)\n",
    "\n",
    "    df = df.rename(columns={'INTERVAL_HR2400_ENERGY_QTY': 'INTERVAL_HR0000_ENERGY_QTY'})\n",
    "\n",
    "    #df = df.drop(['DELIVERY_SERVICE_NAME', 'DELIVERY_SERVICE_CLASS'], axis=1)\n",
    "\n",
    "    print('Reshaping data...')\n",
    "\n",
    "    df = df[selected_columns].melt(\n",
    "        id_vars=[\"ZIP_CODE\", \"ACCOUNT_IDENTIFIER\", \"INTERVAL_READING_DATE\", 'DELIVERY_SERVICE_NAME'],\n",
    "        var_name=\"Time\",\n",
    "        value_name=\"energy\")\n",
    "\n",
    "\n",
    "    df['Time'] = df.Time.map(lambda x: get_HR(x))\n",
    "    df['date_time'] = df.INTERVAL_READING_DATE  + \" \" + df.Time\n",
    "    df['date_time'] = df.date_time.map(lambda x: datetime.datetime.strptime(x,'%m/%d/%Y %H%M')).astype(str)\n",
    "\n",
    "    df = df[['ZIP_CODE', 'ACCOUNT_IDENTIFIER', 'DELIVERY_SERVICE_NAME', 'date_time', 'energy']]\n",
    "\n",
    "    df['zip5'] = df.ZIP_CODE.str[:5]\n",
    "\n",
    "    df = df.rename(columns={'ZIP_CODE': 'zip9','ACCOUNT_IDENTIFIER': 'n_acc', 'DELIVERY_SERVICE_NAME': 'service_name'})\n",
    "\n",
    "\n",
    "    df = df[['zip5', 'n_acc', 'service_name', 'date_time', 'energy']]    \n",
    "     \n",
    "\n",
    "    print('Exporting data...')\n",
    "\n",
    "    df.to_csv(f'data/comed_month/comed_{month}.csv', index=False)\n",
    "\n",
    "    del df\n",
    "    del df_total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df.query('acc_id==@accounts').sort_values('date_time'), x=\"date_time\", y=\"energy\", color='acc_id')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce44fec16a475fa863ad058858edc7cc1f739abe18a15028f7309c6483d88bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
